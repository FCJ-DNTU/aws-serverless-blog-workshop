[
{
	"uri": "https://baoanh020603.github.io/aws-serverless-blog-workshop/1-introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Workshop: Deploying a Serverless Blog Website on AWS With Lambda, API Gateway, DynamoDB, S3 \u0026amp; CloudFront In this workshop, you will learn how to develop a Serverless Blog Website on AWS, using AWS Lambda to handle backend logic, API Gateway to create RESTful APIs, DynamoDB as a NoSQL database, S3 to host static UI (React/Vite), and CloudFront to optimize content delivery performance.\nObjectives: Learn how to design and develop serverless applications on AWS. Create and configure Lambda Functions, API Gateway, DynamoDB, S3, and CloudFront. Deploy a React/Vite frontend application on S3. Connect the frontend to the backend via API Gateway. Manage access between services using AWS IAM. Optimize the free tier and clean up resources. Requirements: AWS account with IAM access (Free tier: https://aws.amazon.com/free). Basic JavaScript skills (Node.js). Tools: Node.js, npm, AWS CLI, Git. (Optional) Postman for API testing. Architecture provided in the Workshop AWS services and costs:\n1. AWS Lambda Uses:\nAWS Lambda is used to run auxiliary functions (getPosts, createPost) to process logic and create posts. Lambda operates on a serverless model, automatically scales and charges on demand. Cost:\nStatus Type Cost/request Cost/month Free Tier 1M free requests, 400,000 GB-sec $0.00 $0.00 Free Tier Ended Requests $0.20/1M, $0.0000167/GB-sec ~$0.01 (100K requests) ~$0.30 (100K requests) 2. Amazon API Gateway What it does:\nAPI Gateway creates HTTP endpoints (GET /posts, POST /posts) to connect the UI to Lambda. Supports RESTful API, request management, and integration with Lambda. Cost:\nStatus Type Cost/request Cost/month Free Tier 1M free requests $0.00 $0.00 Free Tier Ended $3.50/1M requests ~$0.35 (100K requests) ~$10.50 (3M requests) 3. Amazon DynamoDB What it does:\nDynamoDB is a NoSQL database for storing and managing post data (BlogPosts table).\nSupports fast reads/writes and auto-scaling.\nCost:\nStatus Type Cost/day Cost/month Free Tier 25 read/writes, 25GB storage $0.00 $0.00 Free Tier Ended $1.25/1M read, $0.25/1M write, $0.09/GB ~$0.02 (10K read/write, 5GB) ~$0.60 (10K read/write, 5GB) 4. Amazon S3 What it does:\nS3 stores static files of React/Vite UI (HTML, CSS, JS, images). Supports static website hosting. Cost:\nStatus Capacity Cost/day Cost/month Free Tier 5GB Storage, 2,000 GETs, 20,000 PUTs $0.00 $0.00 Free Tier Ended $0.023/GB, $0.005/1,000 GETs ~$0.03 (5GB, GET 10K) ~$1.00 (5GB, GET 10K) 5. Amazon CloudFront What it does:\nCloudFront is a CDN that delivers content from S3 at high speed and HTTPS.\nOffload directly from S3 and improve user experience.\nCost:\nStatus Capacity Cost/day Cost/month Free Tier 1TB bandwidth, 10M requests $0.00 $0.00 Free Tier Ended $0.085/GB, $0.01/10,000 requests ~$0.10 (50GB, 100K requests) ~$3.00 (50GB, 100K requests) 6. I AM What it does:\nIAM manages access to Lambda, API Gateway, and DynamoDB.\nEnsures security by granting specific permissions (e.g. dynamodb:Scan, dynamodb:PutItem).\nCost:\nFree under AWS. 7. Cost Summary\n7.1. Costs while still in Free Tier\nService Type Cost/day Cost/month AWS Lambda 1M requests $0.00 $0.00 Amazon API Gateway 1M requests $0.00 $0.00 Amazon DynamoDB 25 read/write units $0.00 $0.00 Amazon S3 5GB storage $0.00 $0.00 Amazon CloudFront 1TB bandwidth $0.00 $0.00 IAM Free $0.00 $0.00 Total $0.00 $0.00 7.2. Cost after Free Tier expires\nService Type Cost/day Cost/month AWS Lambda 100K requests ~$0.01 ~$0.30 Amazon API Gateway 3M requests ~$0.35 ~$10.50 Amazon DynamoDB 10K reads/writes, 5GB ~$0.02 ~$0.60 Amazon S3 5GB, 10K GETs ~$0.03 ~$1.00 Amazon CloudFront 50GB, 100K requests ~$0.10 ~$3.00 IAM Free $0.00 $0.00 Total ~$0.51 ~$15.40 8. Conclusion\nWhile in the Free Tier, the system operates at $0 cost.\nWhen the Free Tier expires, the system maintenance cost will fluctuate around $15 - $16/month (assuming 100K Lambda requests, 3M API Gateway requests, 10K DynamoDB reads/writes, 5GB S3, 50GB CloudFront).\nIf the system scales, the cost may increase depending on traffic and data.\nActivity flow: 1. Client accesses website\nUser accesses blog via browser. Static content (React/Vite) is stored on S3 and delivered via CloudFront. 2. CloudFront receives requests\nCloudFront serves static content from S3 (HTML, CSS, JS). Forwards API requests (GET /posts, POST /posts) to API Gateway. 3. API Gateway processes requests\nAPI Gateway receives requests from CloudFront and passes them to Lambda functions (getPosts or createPost). Lambda handles backend logic. 4. Lambda queries DynamoDB\nLambda function getPosts calls DynamoDB to get a list of posts. Lambda function createPost saves new posts to DynamoDB. 5. Return results to client\nLambda returns results via API Gateway. API Gateway sends responses to CloudFront. CloudFront can cache responses to optimize speed. Responses are sent to the client via the browser. 6. Manage access rights with IAM\nIAM controls access rights for Lambda (e.g. dynamodb:Scan, dynamodb:PutItem). Ensure security between AWS services. "
},
{
	"uri": "https://baoanh020603.github.io/aws-serverless-blog-workshop/5-configure-api-gateway/5.1-create-rest-api/",
	"title": "Create REST API",
	"tags": [],
	"description": "",
	"content": "Amazon API Gateway Amazon API Gateway is a serverless service that allows you to create and manage RESTful or WebSocket APIs. It acts as a gateway between the frontend (React/Vite) and backend (Lambda functions), handling HTTP requests and forwarding them to AWS services.\nAPI Gateway in the Workshop In this section, we will:\nCreate a REST API to handle HTTP requests.\nCreate a /posts resource to support endpoints for posts.\nEnsure the API integrates with the Lambda functions (getPosts, createPost) in the next step.\nWhy choose API Gateway: Serverless: No need to manage servers, automatically scales with traffic.\nEasy integration: Connects directly to Lambda and supports HTTP requests.\nLow cost: Free Tier offers 1 million free requests per month.\nCreate REST API Go to AWS Management Console. Find and select API Gateway.\nSelect APIs in the navigation menu.\nIn the APIs interface: Select Create API.\nSelect REST API and click Build.\nIn the Create API interface: API name: Enter BlogAPI. Endpoint Type: Select Regional. Click Create API. Create resource /posts: In Resources, select Actions → Create Resource. Resource Name: Enter posts. Resource Path: /posts. Turn on Enable API Gateway CORS (so the frontend can access it). Click Create Resource. Make sure CORS is enabled so that the React/Vite frontend can make requests to the API. Save the API name (BlogAPI) and resource (/posts) for use in the next step.\nDone You have created a REST API and a /posts resource, ready to configure the GET/POST method. "
},
{
	"uri": "https://baoanh020603.github.io/aws-serverless-blog-workshop/",
	"title": "Workshop: Building an End-to-End Machine Learning Pipeline on AWS with Lambda, API Gateway, S3, SageMaker &amp; DynamoDB",
	"tags": [],
	"description": "",
	"content": "Workshop: Building an End-to-End Machine Learning Pipeline on AWS with Lambda, API Gateway, S3, SageMaker \u0026amp; DynamoDB Overview In this workshop, you will learn how to build and deploy an end-to-end machine learning pipeline on AWS.\nWe will use AWS Lambda for preprocessing and inference, API Gateway to expose RESTful endpoints, S3 for data storage, Amazon SageMaker for model training and hosting, DynamoDB for metadata storage, and CloudWatch for monitoring and logging.\nObjectives: Understand how to design and deploy a complete ML pipeline on AWS. Build and configure data ingestion, preprocessing, and model training workflows. Deploy and manage machine learning models with Amazon SageMaker. Expose inference endpoints through API Gateway and Lambda. Integrate DynamoDB for model metadata and monitoring with CloudWatch. Learn best practices for IAM permissions and cost optimization. Requirements: AWS account with IAM access (Free Tier: https://aws.amazon.com/free) Basic knowledge of Python or Go (for Lambda functions and ML scripts) Familiarity with REST APIs and JSON Tools: AWS CLI, Git, Docker (optional), and a web browser (Optional) Postman for testing inference endpoints Contents Introduction Set Up AWS Account and IAM Permissions Create S3 Bucket for Data Storage Implement Lambda Preprocessing Function Train and Register Model with Amazon SageMaker Deploy SageMaker Endpoint for Inference Build Lambda Inference Function and API Gateway Integrate DynamoDB and CloudWatch Clean Up Resources "
},
{
	"uri": "https://baoanh020603.github.io/aws-serverless-blog-workshop/5-configure-api-gateway/5.2-api-test-configuration/",
	"title": "Configure and Test API",
	"tags": [],
	"description": "",
	"content": "Configure API Gateway In this section, we will:\nAdd GET and POST methods to the /posts resource to retrieve and add posts.\nIntegrate with Lambda functions (getPosts, createPost).\nEnable CORS and deploy the API for use in the frontend.\nTest the API to ensure proper operation.\nReasons for configuring and testing: HTTP request handling: GET/POST methods allow the frontend to interact with the backend.\nLambda integration: Connect the API to Lambda to handle business logic.\nPerformance testing: Ensure the API returns correct results before integrating with the frontend.\nConfigure and Test API Go to AWS Management Console and select API Gateway.\nOpen the BlogAPI API created in the previous step.\nCreate a GET method for /posts:\nIn Resources, select the /posts resource.\nSelect Actions → Create Method.\nSelect GET from the dropdown.\nIntegration type: Select Lambda Function.\nLambda Function: Select getPosts.\nClick Save and confirm IAM permissions if prompted.\nCreate a POST method for /posts: Repeat step 3, but select POST and integrate with the createPost function. Configure CORS: In Resources, select Actions → Enable CORS.\nAccept the default values ​​and click Enable CORS and replace existing CORS headers.\nDeploy API: Select Actions → Deploy API.\nDeployment stage: Select [New Stage] and name it (e.g. prod).\nClick Deploy.\nSave Invoke URL (e.g. https://gcnpmry3bd.execute-api.ap-southeast-1.amazonaws.com/prod).\nMake sure CORS is enabled so that the React/Vite frontend can make requests to the API. Save the Invoke URL for use in the frontend (step 6). Check the IAM permissions of Lambda (lambda-blog-role) to ensure that API Gateway can call functions.\nTest the API: Use Postman or a browser to test:\nGET \u0026lt;Invoke URL\u0026gt;/posts: Returns a list of posts from DynamoDB.\nPOST \u0026lt;Invoke URL\u0026gt;/posts with body:\n{ \u0026#34;postId\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Test Post\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;This is a test post.\u0026#34; } Check the result in DynamoDB (Explore table items tab). Confirm and continue: The API is up and running and ready to connect to the frontend.\nRecord the Invoke URL for use in the frontend configuration step.\nDone You have configured and tested the API to handle GET/POST requests. "
},
{
	"uri": "https://baoanh020603.github.io/aws-serverless-blog-workshop/2-set-up-aws-account-and-iam-permissions/",
	"title": "Setting up an AWS account and IAM permissions",
	"tags": [],
	"description": "",
	"content": " Best practice, avoid using Root User. Instead, create an IAM Role with minimal permissions for Lambda to access DynamoDB, ensuring security and ease of management.\nIn this section, we will create an IAM Role and Policy to allow Lambda functions (getPosts and createPost) to interact with the BlogPosts table in DynamoDB, limited to the us-east-1 region (or your chosen region).\n1. Access the AWS IAM Management Console Log in to the AWS Management Console. Access IAM Console 2. Create Custom Policy 2.1. In the left navigation bar, select Policies\n2.2. At the Policies interface, select Create policy.\n2.3. Step 1 - Specify permissions\nSelect JSON tab and paste the JSON below into Policy Editor, then select Next:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:Scan\u0026#34;, \u0026#34;dynamodb:PutItem\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:us-east-1:*:table/BlogPosts\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:RequestedRegion\u0026#34;: \u0026#34;us-east-1\u0026#34; } } }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } This policy allows Lambda to perform dynamodb:Scan (get posts) and dynamodb:PutItem (create posts) on the BlogPosts table in the us-east-1 region. CloudWatch Logs permissions allow Lambda to write logs.\n3. Create IAM Role for Lambda IAM Role is assigned to Lambda functions to grant access. The lambda-dynamodb-access policy will be attached to this role.\n3.1. Go to Roles in the IAM Console. 3.2. Select Create role. 3.3. In the Create role interface: Select AWS service as the trusted entity type. Select Lambda in the use case. Click Next.\n3.4. In Add permissions: Find and select the lambda-dynamodb-access policy. (Optional) Add AWSLambdaBasicExecutionRole for basic CloudWatch Logs permissions. Click Next.\n3.5. In Name, review, and create: Role name: lambda-blog-role. Description: Role for Lambda to access DynamoDB BlogPosts table. Click Create role.\n4. Assign IAM Role to Lambda Functions 4.1. Go to the Lambda Console. 4.2. Open the getPosts function: Go to Configuration → Permissions. Click Edit on the execution role. Choose Existing role → lambda-blog-role. Save.\n4.3. Repeat for the createPost function. 4.4. Verify in the IAM Console: Open the lambda-blog-role. Ensure the lambda-dynamodb-access policy is attached. Confirm the DynamoDB ARN matches your table.\n5. Test the IAM Role with Lambda 5.1. Log in with an IAM User (not Root). 5.2. Test getPosts function in Lambda: Go to the Test tab, create an event with {}. Click Test. Expected result:\n{ \u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;[]\u0026#34;, \u0026#34;headers\u0026#34;: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34; } } (or existing posts if the table has data).\n5.3. If AccessDenied errors appear: Check CloudWatch Logs. Verify ARN matches your table. Confirm region = us-east-1. Ensure environment variable TABLE_NAME=BlogPosts.\nDone! You have created an IAM Role and Policy for Lambda to access DynamoDB.\n"
},
{
	"uri": "https://baoanh020603.github.io/aws-serverless-blog-workshop/3-create-dynamodb-table/3.1-create-dynamodb-table/",
	"title": "Create DynamoDB Table",
	"tags": [],
	"description": "",
	"content": "What is DynamoDB? Amazon DynamoDB is a serverless NoSQL database that provides high-performance, scalable data storage and retrieval, and integrates well with AWS services like Lambda.\nWhy create a DynamoDB table? Post data storage: Create a BlogPosts table to store information such as ID, title, content, and creation date of a post.\nServerless support: DynamoDB does not require server management, suitable for Lambda and API Gateway architectures.\nHigh performance: Ensures fast queries and automatically scales according to traffic.\nSteps: Go to AWS Management Console. Select the Amazon DynamoDB service. In the navigation menu, select Tables Select Create table. In the Create table interface: Table name: Enter BlogPosts.\nPartition key: Enter postId (type String) as the primary key to uniquely identify each post.\nSettings: Select Default settings (On-demand mode, suitable for Free Tier).\nClick Create table.\n6. Check the table:\nAfter creation, the BlogPosts table will appear in the Tables list with the status Active. Make sure the table name is BlogPosts, because Lambda functions (getPosts, createPost) will use this name in the environment variable TABLE_NAME. Create a table in the same region as the Lambda functions (e.g. us-east-1). The Lambda IAM Role needs the dynamodb:Scan and dynamodb:PutItem permissions (configured in the previous step). Done You have created a BlogPosts table to store your post data. "
},
{
	"uri": "https://baoanh020603.github.io/aws-serverless-blog-workshop/3-create-dynamodb-table/",
	"title": "Prepare DynamoDB",
	"tags": [],
	"description": "",
	"content": "In this section, we will create a DynamoDB table and add sample data Test Table, Test Query and Understand Data Structure.\nContent:\n3.1. Create DynamoDB Table 3.2. Add sample data "
},
{
	"uri": "https://baoanh020603.github.io/aws-serverless-blog-workshop/3-create-dynamodb-table/3.2-add-sample-data/",
	"title": "Add Sample Data",
	"tags": [],
	"description": "",
	"content": "Why add sample data? Test table: Adding sample data to the BlogPosts table helps verify that the table works properly before integrating with Lambda functions.\nTest query: Sample data allows testing that the Lambda function getPosts returns the desired results.\nUnderstand data structure: Helps familiarize yourself with how data is stored in DynamoDB.\nSteps: Go to AWS Management Console and go to the Amazon DynamoDB service.\nIn the Tables list, select the BlogPosts table.\nSelect the Explore table items tab.\nSelect Create item.\nAdd the following properties:\npostId (String): 1 title (String): Sample Post content (String): This is a sample blog post. createdAt (String): 2025-08-20T12:00:00Z Click Create item. Sample data to test that the Lambda function getPosts returns the correct result. Make sure the properties (postId, title, content, createdAt) match the expected structure in the Lambda functions. If adding multiple items, make sure each postId is unique. Done You\u0026rsquo;ve added sample data to the BlogPosts table, ready to test with Lambda. "
},
{
	"uri": "https://baoanh020603.github.io/aws-serverless-blog-workshop/4-create-lambda-functions/",
	"title": "Create Lambda Functions",
	"tags": [],
	"description": "",
	"content": "AWS Lambda AWS Lambda is a serverless service that allows you to run code without managing servers. It automatically scales with traffic and only charges when your code is executed, making it ideal for applications like backend APIs.\nWhat is a Lambda Function? Lambda Function is a piece of code (written in Node.js, Python, etc.) deployed on AWS Lambda to handle specific tasks, like retrieving data from DynamoDB or handling API requests.\nLambda Deployment Model in Workshop In this workshop, we will create two Lambda functions:\ngetPosts: Retrieves a list of posts from the BlogPosts table in DynamoDB. createPost: Add new posts to the BlogPosts table. These functions will: Integrate with API Gateway to handle HTTP requests. Use IAM Role (created in the previous step) to access DynamoDB. Written in Node.js with AWS SDK v3. Reasons to choose Lambda: Serverless: No need to manage servers, reduce operating costs. Low cost: Free Tier provides 1 million free requests per month, suitable for testing. Easy integration: Works well with API Gateway and DynamoDB. Reasons to choose Node.js: Popular: Good support for web and serverless applications. AWS SDK v3: Provides lightweight modules (like @aws-sdk/client-dynamodb) to optimize performance. Large Community: Easy to find documentation and support libraries. Create Lambda Functions 1. Access AWS Console Open a browser and access Lambda Console 2. Create the function getPosts In Lambda Dashboard, select Create function. 3. Configure the function In the Create function section:\nFunction name: Enter getPosts.\nRuntime: Select Node.js 20.x.\nRole: Select Use an existing role and select lambda-blog-role (created in the IAM step).\nClick Create function.\n4. Add code for getPosts In the function interface, select the Code tab. Replace the default code in index.mjs with the following code: import { DynamoDBClient, ScanCommand } from \u0026#39;@aws-sdk/client-dynamodb\u0026#39;; const dynamodb = new DynamoDBClient({}); export const handler = async () =\u0026gt; { const params = { TableName: process.env.TABLE_NAME }; try { const data = await dynamodb.send(new ScanCommand(params)); return { statusCode: 200, body: JSON.stringify(data.Items || []), headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39; } }; } catch (err) { console.error(\u0026#39;Error:\u0026#39;, err); return { statusCode: 500, body: JSON.stringify({ error: \u0026#39;Could not retrieve posts\u0026#39; }) }; } }; Add environment variables: In the Configuration → Environment variables tab, select Edit. Add: TABLE_NAME = BlogPosts. Click Save.\n5. Create function createPost Repeat steps 2-3 to create a new function with: Function name: createPost. Runtime: Node.js 20.x. Role: lambda-blog-role.\nReplace the code in index.mjs with:\nimport { DynamoDBClient, PutItemCommand } from \u0026#39;@aws-sdk/client-dynamodb\u0026#39;;\rimport { marshall } from \u0026#39;@aws-sdk/util-dynamodb\u0026#39;;\rconst dynamodb = new DynamoDBClient({});\rexport const handler = async (event) =\u0026gt; { const body = JSON.parse(event.body || \u0026#39;{}\u0026#39;); const params = { TableName: process.env.TABLE_NAME, Item: marshall({ postId: body.postId || Date.now().toString(), title: body.title || \u0026#39;Untitled\u0026#39;, content: body.content || \u0026#39;\u0026#39;, createAt: new Date().toISOString() }) }; try { await dynamodb.send(new PutItemCommand(params)); return { statusCode: 200, body: JSON.stringify({ message: \u0026#39;Post created successfully\u0026#39; }), headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39; } }; } catch (err) { console.error(\u0026#39;Error:\u0026#39;, err); return { statusCode: 500, body: JSON.stringify({ error: \u0026#39;Could not create post\u0026#39; }) }; }\r}; Add environment variable TABLE_NAME = BlogPosts as in step 4.\n6. Configure package.json To add dependencies @aws-sdk/client-dynamodb and @aws-sdk/util-dynamodb, create a package.json file in the source code directory:\n{\r\u0026#34;name\u0026#34;: \u0026#34;lambda-blog\u0026#34;,\r\u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;,\r\u0026#34;type\u0026#34;: \u0026#34;module\u0026#34;,\r\u0026#34;dependencies\u0026#34;: {\r\u0026#34;@aws-sdk/client-dynamodb\u0026#34;: \u0026#34;^3.0.0\u0026#34;,\r\u0026#34;@aws-sdk/util-dynamodb\u0026#34;: \u0026#34;^3.0.0\u0026#34;\r}\r} Package the code: Create a local directory for each function (e.g. getPosts/, createPost/). Run npm install in each directory. Compress the directory into a .zip file (including node_modules, index.mjs, package.json). Upload the .zip file to Lambda in the Code → Upload from → .zip file tab. Make sure to use ES Module (index.mjs) and handler is index.handler. The .zip file must include node_modules to avoid missing dependency errors. The environment variable TABLE_NAME must match the DynamoDB table name (BlogPosts).\n7. Test Lambda Functions In the interface of each function, select the Test tab:\nFor getPosts, create an event with empty JSON {}.\rFor createPost, create a sample event:{\r\u0026#34;body\u0026#34;: \u0026#34;{\\\u0026#34;postId\\\u0026#34;: \\\u0026#34;1\\\u0026#34;, \\\u0026#34;title\\\u0026#34;: \\\u0026#34;Test Post\\\u0026#34;, \\\u0026#34;content\\\u0026#34;: \\\u0026#34;This is a test post.\\\u0026#34;}\u0026#34;\r} Click Test and check the result: getPosts: Returns a list of posts (or an empty array if there is no data yet). createPost: Returns the message { \u0026ldquo;message\u0026rdquo;: \u0026ldquo;Post created successfully\u0026rdquo; }. "
},
{
	"uri": "https://baoanh020603.github.io/aws-serverless-blog-workshop/5-configure-api-gateway/",
	"title": "Create REST API and Configure and Test API",
	"tags": [],
	"description": "",
	"content": "Configure and Test API In this lab, we will create REST API and configure and test API\nContent 5.1 Create REST API 5.2 Configure and Test API "
},
{
	"uri": "https://baoanh020603.github.io/aws-serverless-blog-workshop/6-prepare-frontend-application/",
	"title": "Prepare Frontend Application",
	"tags": [],
	"description": "",
	"content": "\nFrontend Application The blog application\u0026rsquo;s frontend is a web interface built with React and Vite, allowing users to view a list of posts and create new posts via the Gateway API. The frontend will be hosted on S3 and distributed via CloudFront (following steps).\nFrontend in the Workshop In this section, we will:\nCreate a React/Vite project.\nConfigure the application to call the Gateway API (GET /posts, POST /posts).\nAdd basic interface components (article list, article creation form).\nPackage the application for deployment to S3.\nBenefits of using React/Vite: High performance: Vite provides fast build times and smooth development experience.\nPopular: React has a large community, easy to integrate with RESTful API.\nReusability: React components help build flexible and easy-to-maintain interfaces.\nCompatible with S3/CloudFront: Easy to deploy static applications.\nPrice of Frontend Development cost: Free (using open source tools such as React, Vite).\nDeployment cost: Calculated in S3 and CloudFront (steps 7, 8). Free Tier provides:\nS3: 5GB storage, 20,000 GET requests, 2,000 PUT requests free/month.\nCloudFront: 1TB of data transfer/month free.\nWhich configuration should we choose for this workshop? We will use React with Vite because:\nVite has a fast build speed, suitable for small applications such as blogs.\nReact is easy to integrate with API Gateway via the axios or fetch library.\nSimple structure, easy to deploy to S3 as a static site.\nPrepare the Frontend application Set up the development environment Make sure you have Node.js (recommended version 20.x) and npm installed.\nInstall Vite and create a React project:\nnpm create vite@latest blog-frontend -- --template react cd blog-frontend npm install Install additional libraries Install axios to call API Gateway: npm install axios Configure source code Replace the content of the src/App.jsx file with the following code to display the list of posts and the post creation form: import { useState, useEffect } from \u0026#39;react\u0026#39;; import axios from \u0026#39;axios\u0026#39;; import \u0026#39;./App.css\u0026#39;; const API_URL = \u0026#39;\u0026lt;Invoke URL\u0026gt;/posts\u0026#39;; // Replace with Invoke URL from step 5 function App() { const [posts, setPosts] = useState([]); const [title, setTitle] = useState(\u0026#39;\u0026#39;); const [content, setContent] = useState(\u0026#39;\u0026#39;); // Get list of posts useEffect(() =\u0026gt; { axios.get(API_URL) .then(response =\u0026gt; setPosts(response.data)) .catch(error =\u0026gt; console.error(\u0026#39;Error fetching posts:\u0026#39;, error)); }, []); // Submit new posts const handleSubmit = async (e) =\u0026gt; { e.preventDefault(); try { await axios.post(API_URL, { postId: Date.now().toString(), title, content. content }); setTitle(\u0026#39;\u0026#39;); setContent(\u0026#39;\u0026#39;); // Refresh the post list const response = await axios.get(API_URL); setPosts(response.data); } catch (error) { console.error(\u0026#39;Error creating post:\u0026#39;, error); } }; return ( \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;Serverless Blog\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt;Create Post\u0026lt;/h2\u0026gt; \u0026lt;form onSubmit={handleSubmit}\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; value={title} onChange={(e) =\u0026gt; setTitle(e.target.value)} placeholder=\u0026#34;Title\u0026#34; required. required /\u0026gt; \u0026lt;textarea value={content} onChange={(e) =\u0026gt; setContent(e.target.value)} placeholder=\u0026#34;Content\u0026#34; required. required /\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;Create Post\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;h2\u0026gt;Posts\u0026lt;/h2\u0026gt; \u0026lt;ul\u0026gt; {posts.map(post =\u0026gt; ( \u0026lt;li key={post.postId.S}\u0026gt; \u0026lt;h3\u0026gt;{post.title.S}\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;{post.content.S}\u0026lt;/p\u0026gt; \u0026lt;small\u0026gt;{post.createdAt.S}\u0026lt;/small\u0026gt; \u0026lt;/li\u0026gt; ))} \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; ); } export default App; Update src/App.css file to add basic styles: body { font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; } input, textarea { display: block; width: 100%; margin: 10px 0; padding: 8px; } button { padding: 8px 16px; background-color: #007bff; color: white; border: none; cursor: pointer; } button:hover { background-color: #0056b3; } ul { list-style: none; padding: 0; } li { margin-bottom: 20px; border-bottom: 1px solid #ddd; padding-bottom: 10px; } Configure API URL Replace \u0026lt;Invoke URL\u0026gt; in src/App.jsx with Invoke URL from step 5 (API Gateway), for example: https://\u0026lt;api-id\u0026gt;.execute-api.\u0026lt;region\u0026gt;.amazonaws.com/prod/posts. Test the application Run the application locally: npm run dev Open a browser at http://localhost:5173 to test:\nView the list of posts from API Gateway (GET /posts).\nCreate a new post via form (POST /posts).\nIf you encounter errors (e.g. CORS or API not responding):\nCheck Invoke URL and CORS in API Gateway.\nView console logs in browser or Lambda\u0026rsquo;s CloudWatch Logs.\nPackaging the App Build the app to generate static files: npm run build The result will be in the dist/ folder, ready to upload to S3. Make sure the Invoke URL in src/App.jsx matches the URL from the API Gateway. Check CORS in the API Gateway to avoid errors when calling the API from the browser. Files in the dist/ folder must be uploaded to S3 in the next step.\nDone You have created and configured a React/Vite frontend app, ready to deploy to S3. "
},
{
	"uri": "https://baoanh020603.github.io/aws-serverless-blog-workshop/7-host-frontend-on-s3/",
	"title": "Host Frontend on S3",
	"tags": [],
	"description": "",
	"content": "\nAmazon S3 Amazon S3 (Simple Storage Service) is an object storage service from AWS that allows storing and serving static files such as HTML, CSS, JavaScript, and images. In this project, S3 is used to host a React/Vite frontend application as a static website.\nS3 in the Workshop In this section, we will:\nCreate an S3 bucket to store the static files of the frontend application (the dist/ folder from step 6).\nEnable Static website hosting on S3.\nUpload static files from React/Vite projects.\nConfigure public access so users can access the website.\nBenefits of using S3: Low cost: Free Tier provides 5GB storage, 20,000 GET requests, and 2,000 PUT requests for free per month.\nEasy to deploy: Supports static website hosting, suitable for React/Vite applications.\nIntegrated with CloudFront: Accelerates content delivery and supports HTTPS (step 8).\nHigh durability: Ensures data safety with 99.999999999% durability.\nCreate and configure S3 Bucket Access AWS Management Console Find and select S3 in AWS Console. Create S3 Bucket In the S3 interface, select Buckets → Create bucket.\nBucket name: Enter a unique name, for example: blog-workshop-\u0026lt;your-account-id\u0026gt;.\nRegion: Select the same region as the API Gateway (for example: us-east-1).\nObject Ownership: Select ACLs disabled.\nBlock Public Access settings: Keep the default (will be updated later).\nClick Create bucket.\nEnable Static Website Hosting Open the bucket you just created, select the Properties tab.\nScroll down to Static website hosting, select Edit.\nSelect Enable.\nIndex document: Enter index.html.\nClick Save changes.\nSave the Bucket website endpoint (e.g. http://blog-workshop-\u0026lt;your-account-id\u0026gt;.s3-website-\u0026lt;region\u0026gt;.amazonaws.com).\nConfigure access rights In the Permissions tab, select Edit under Block public access.\nUncheck Block all public access and its sub-options, click Save changes.\nIn Bucket policy, select Edit and add the following policy:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::blog-workshop-\u0026lt;your-account-id\u0026gt;/*\u0026#34; } ] } Click Save changes. Upload frontend files In the code/frontend/ folder (from step 6), run the build command if you haven\u0026rsquo;t done so already: cd code/frontend\rnpm run build In the bucket, select Upload and upload the entire dist/ folder.\nMake sure all files (HTML, CSS, JS) are uploaded with the default Content-Type.\nTest the website Visit the Bucket website endpoint in your browser (e.g. http://blog-workshop-\u0026lt;your-account-id\u0026gt;.s3-website-\u0026lt;region\u0026gt;.amazonaws.com).\nCheck the post list and post creation form.\nIf you encounter an error (e.g. 403 Forbidden):\nCheck the bucket policy and public access.\nVerify the Invoke URL in src/App.jsx matches the API Gateway.\nCheck the browser console logs or Lambda\u0026rsquo;s CloudWatch Logs.\nThe bucket name must be globally unique (add \u0026lt;your-account-id\u0026gt; to avoid duplicates). Make sure the bucket policy allows s3:GetObject to be public. Save the Bucket website endpoint for use in the CloudFront configuration step.\nDone You\u0026rsquo;ve created an S3 bucket, enabled static website hosting, and uploaded your frontend application. "
},
{
	"uri": "https://baoanh020603.github.io/aws-serverless-blog-workshop/8-configure-cloudfront/",
	"title": "Amazon CloudFront",
	"tags": [],
	"description": "",
	"content": "Amazon CloudFront Amazon CloudFront is a CDN (Content Delivery Network) service from AWS, which helps deliver static (HTML, CSS, JavaScript) and dynamic (API) content at high speed and secure HTTPS. In this project, CloudFront is used to distribute the frontend application from S3, improve performance and add HTTPS.\nContents 8.1 Create CloudFront Distribution 8.2 Update and check CloudFront "
},
{
	"uri": "https://baoanh020603.github.io/aws-serverless-blog-workshop/8-configure-cloudfront/8.1-create-cloudfront-distribution/",
	"title": "Create CloudFront Distribution",
	"tags": [],
	"description": "",
	"content": "Amazon CloudFront Amazon CloudFront is a CDN (Content Delivery Network) service from AWS, which helps deliver static (HTML, CSS, JavaScript) and dynamic (API) content at high speed and secure HTTPS. In this project, CloudFront is used to distribute frontend applications from S3, improve performance and add HTTPS.\nCloudFront in the Workshop In this section, we will:\nCreate a CloudFront distribution to deliver content from an S3 bucket.\nConfigure Origin Access Control (OAC) to secure access to the bucket.\nSet basic settings such as HTTPS and HTTP methods.\nBenefits of using CloudFront: High speed: Distribute content across global edge locations.\nSecurity: HTTPS support, AWS WAF integration (optional).\nLow cost: Free Tier provides 1TB of data transfer per month.\nIntegrated with S3: Easily connect to a bucket containing static files.\nCreate CloudFront Distribution Go to AWS Management Console Find and select CloudFront in AWS Console. Create Distribution In the CloudFront interface, select Distributions → Create distribution. Distribution Configuration Origin domain: Select the S3 bucket you created (e.g. blog-workshop-\u0026lt;your-account-id\u0026gt;).\nOrigin access: Select Origin access control settings (recommended).\nOrigin access control: Select Create new OAC.\nIn Create new OAC, keep the default and click Create.\nGo back and select the OAC you just created.\nViewer protocol policy: Select Redirect HTTP to HTTPS.\nAllowed HTTP methods: Select GET, HEAD, OPTIONS, PUT, POST, PATCH, DELETE.\nWeb Application Firewall (WAF): Select Do not enable security protections.\nKeep the rest as default, scroll down and click Create distribution.\nWait for Distribution to initialize The initialization process takes about 4-5 minutes.\nOnce completed, note down the Distribution domain name (e.g. d1234567890abcdef.cloudfront.net).\nMake sure to select the correct S3 bucket as origin. Save the Distribution domain name for checking and use in the next step. OAC requires updating the bucket policy (will be done in step 8.2).\nDone You have created a CloudFront distribution to distribute your frontend application. "
},
{
	"uri": "https://baoanh020603.github.io/aws-serverless-blog-workshop/9-clean-up-resources/",
	"title": "Clean Up Resources",
	"tags": [],
	"description": "",
	"content": "Clean Up Resources After completing the workshop, it’s essential to clean up AWS resources to avoid unexpected costs beyond the Free Tier. This section guides you through deleting the resources created: CloudFront, S3, API Gateway, Lambda, DynamoDB, and IAM.\nWhy Clean Up: Cost Savings: Prevent unnecessary charges from unused resources. Security: Remove IAM permissions and resources to avoid unauthorized access. Organization: Keep your AWS account tidy for future projects. Clean Up Resources Delete CloudFront Distribution\nGo to CloudFront. Select the distribution you created (e.g., d1234567890abcdef.cloudfront.net). Click Disable, wait for the status to change to Disabled. Click Delete to remove the distribution. Delete S3 Bucket\nGo to S3. Select the bucket you created (e.g., blog-workshop-\u0026lt;your-account-id\u0026gt;). Click Empty, type permanently delete to confirm, then select Empty. After the bucket is emptied, click Delete, enter the bucket name in the confirmation field, and click Delete bucket. Delete API Gateway\nGo to API Gateway. Select the BlogAPI API. Click Actions → Delete, enter the API name to confirm, then click Delete. Delete Lambda Functions\nGo to Lambda. Select the getPosts function, click Actions → Delete, and confirm. Repeat for the createPost function. Delete DynamoDB Table\nGo to DynamoDB. Select the Posts table. Click Actions → Delete table, enter the table name to confirm, then click Delete. Clean Up IAM Resources\nGo to IAM. Under Policies, select the lambda-blog-policy (or similar), click Delete, and confirm. Under Roles, select the lambda-blog-role, click Delete, and confirm. Ensure the S3 bucket is emptied before deleting it. Double-check resources to avoid deleting those used by other projects. If deletion fails (e.g., resources in use), check dependencies (like Lambda permissions or API Gateway integrations).\nDone You have successfully cleaned up all resources related to the workshop, preventing further costs. "
},
{
	"uri": "https://baoanh020603.github.io/aws-serverless-blog-workshop/8-configure-cloudfront/8.2-check-cloudfront/",
	"title": "Update and Test CloudFront",
	"tags": [],
	"description": "",
	"content": "\nUpdate and Test CloudFront In this section, we will:\nUpdate the bucket policy so that CloudFront can access S3 via Origin Access Control (OAC).\nTest the frontend application via CloudFront domain.\nConfirm that the website works with HTTPS.\nReasons to update and test: Security: OAC limits S3 access to CloudFront only, increasing security.\nVerify Activity: Make sure the website displays correctly and the API works over HTTPS.\nPreparing to Finish: Connect the entire system (frontend, backend, CDN).\nUpdate and Test CloudFront Update Bucket Policy Access the S3 bucket (blog-workshop-\u0026lt;your-account-id\u0026gt;), select the Permissions tab.\nIn Bucket policy, select Edit and replace the current policy with the following policy (replace \u0026lt;your-bucket-name\u0026gt; and \u0026lt;oac-id\u0026gt; with the bucket name and OAC ID from step 8.1):\n{ \u0026#34;Version\u0026#34;: \u0026#34;2008-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;PolicyForCloudFrontPrivateContent\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::cloudfront:user/CloudFront Origin Access Identity \u0026lt;oac-id\u0026gt;\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::\u0026lt;your-bucket-name\u0026gt;/*\u0026#34; } ] } Click Save changes. Disable Public Access In Permissions, select Edit under Block public access.\nEnable Block all public access and all sub-options, click Save changes.\nThis ensures that only CloudFront can access the bucket.\nTest Website via CloudFront Access the Distribution domain name from step 8.1 (e.g. https://d1234567890abcdef.cloudfront.net) in your browser.\nCheck the post list and post creation form.\nTry creating a new post to confirm API Gateway works over HTTPS.\nDebug errors (if any) If the website does not display:\nCheck the bucket policy for the correct OAC ID and bucket name.\nVerify that the index.html file exists in the bucket.\nIf the API does not work:\nCheck the Invoke URL in src/App.jsx (step 6).\nVerify CORS in API Gateway (step 5.2).\nCheck the browser console log or Lambda\u0026rsquo;s CloudWatch Logs.\nMake sure the bucket policy uses the correct OAC ID and bucket name. Only access the website via Distribution domain name (HTTPS), not using Bucket website endpoint (HTTP). If you get a 403 error, check the OAC and bucket policy.\nDone You have updated your bucket policy and tested your application over CloudFront with HTTPS. "
},
{
	"uri": "https://baoanh020603.github.io/aws-serverless-blog-workshop/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://baoanh020603.github.io/aws-serverless-blog-workshop/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]